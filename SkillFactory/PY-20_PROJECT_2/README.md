# Проект: Анализ вакансий из HeadHunter

## Оглавление
[1. Описание проекта;](https://github.com/vadimkopytko/learning/blob/main/SkillFactory/PY-17_PROJECT-1/README.md#Описание-проекта)  
[2. Краткая информация о данных;](https://github.com/vadimkopytko/learning/blob/main/SkillFactory/PY-17_PROJECT-1/README.md#Краткая-информация-о-данных)  
[3. Этапы работы над проектом;](https://github.com/vadimkopytko/learning/blob/main/SkillFactory/PY-17_PROJECT-1/README.md#Этапы-работы-над-проектом)  
[4. Результаты;](https://github.com/vadimkopytko/learning/blob/main/SkillFactory/PY-17_PROJECT-1/README.md#Результаты)  
[5. Использованные инструменты и библиотеки;](https://github.com/vadimkopytko/learning/blob/main/SkillFactory/PY-17_PROJECT-1/README.md#Использованные-инструменты-и-библиотеки)   



### Описание проекта
Мы имеем базу данных о вакансиях с HeadHunter. Необзодимо провести анализ данных для создания модели машинного обучения, которая будет рекомендовать вакансии клиентам агентства, претендующим на позицию Data Scientist. Сначала вам необходимо понять, что из себя представляют данные и насколько они соответствуют целям проекта.

Основные этапы исследования и обработки данных следующие:
1. Предварительный анализ данных;
2. Детальный анализ вакансий;
3. Анализ работодателей;
4. Предметный анализ.

### Краткая информация о данных
База вакансий, выгруженная с сайта поиска вакансий hh.ru, расположенная в реляционной БД
Для подключения к серверу использовалась библиотека psycopg2, запросы к БД написаны на PostgreSQL.

### Этапы работы над проектом
**1. Предварительный анализ данных**  
**Цель:** познакомиться с таблицами и данными в них, определить ключевые поля и связи между таблицами.

**2. Детальный анализ вакансий**  
**Цель:** провести более грубокий анализ данных внутри каждой таблицы, формирование топов и флопов по разным признакам, определение общих тенденций в данных.

**3. Анализ работодателей**  
**Цель:** провести детальный анализ работодалей по различным качественным признакам, выявление некачественных данных, анализ данных на конретных примерах.

**4. Предметный анализ**  
**Цель:**  проанализировать вакансии в сфере о данных, выявить закономерности, понять, требования к вакансиям в данной области. 

### Результаты
**1. Предварительный анализ данных**  
**Результаты этапа:** по результатам анализа на данном этапе получили следующие выводы:
* общее количество вакансий - 49 197;
* общее количесво работодателей - 23501;
* общее количество регионов - 1362;
* общее количество сфер деятельности - 294.


**2. Детальный анализ вакансий**  
**Результаты этапа:**  по результатам анализа на данном этапе получили следующие выводы:
* наибольшее количество вакансий наблюдается в крупных-городах, а точнее столицах и городах-миллионниках. Так на 1 месте - Москва (5 333 вакансий), на втором - Санкт-Петербург (2 851 вакансий), на третьем - Минск (2 112 вакансий);
* у 49% вакансий от общего числа вакансий (24 073 вакансии) заполнено хотя бы одно поле по вилке заработной платы;
* средняя вилка по заработной плате находится в диапазоне от 71 065 руб. до 110 537 руб.;
* наиболее предпочтительным видом трудоустройства является полная занятость с удаленным графиком работы;
* согласно перечню вакансий наиболее востребованы специалисты с опытом работы свыше 6 лет, на втором месте - вакансий, на которые не требуется опыт работы, после специалисты с опытом работы от 3 до 6 лет, и в заключении - от 1 года до 3 лет. 


**3. Анализ работодателей** 
**Результаты:** по результатам анализа на данном этапе получили следующие выводы:
 топ-5 работодателей по количеству вакансий в порядке убывания: Яндекс, Ростелеком, Тинькофф, СБЕР, Газпром нефть;
* работодатели, которые в качестве региона имеют не город, а страну, имеют множество работодателей, но не имеют при этом вакансий: Россия, Казахстан, Московская область, Краснодарский край, Ростовская область;
* Наибольшее количество регионов, в которых размещены вакансии, предлагает компания Яндекс;
* 8 419 компаний не указали свою сферу деятельности;
* 3 553 компаний указали в сфере деятельности "Разработку программного обеспечения";
* компания Яндекс разместила 485 вакансий в городах-миллионниках, с наибольшим количеством в порядке убывания в Москве (54 вакансии), Санкт-Петербурге (42 вакансии) и Екатеринбурге (39 вакансий)

**4. Предметный анализ**  
**Результаты:** по результатам анализа на данном этапе получили следующие выводы:
* 1 771 вакансия из всего перечня связаны с данными;
* из них 51 вакансия предлагает работу для начинающих специалистов;
* для 201 вакансии (без учета начинающих специалистов) обязательными навыками являются владение SQL или postgres;
* для 351 вакансии (без учета начинающих специалистов) обязательнымм навыком является владение python;
* пордяка 6,4 навыков являюся средним значением для вакансий в области данных;
* среднее предложение по заработной платы для специалистов с опытом рабооты от 3 до 6 лет составляет 243 115 руб.

**Итоговый результат:**
* в базе данных содержится около 49 тыс. вакансий среди 23 тыс. работодателей;
* вакансии рассредоточены среди 1,3 тыс городов России и стран СНГ. Наибольшее количество вакансий находится в городах-столицах и крупных городах-миллионниках;
* средняя вилка по заработной плате находится в диапазоне от 71 065 руб. до 110 537 руб.;
* если смотреть на вакансии в сфере данных, то количество вакансий всего 1,8 тыс., что составляет примерно 4% от общего числа вакансий. При этом для начинающих специалистов предложений совсем мало, все 51 вакансия, что говорит о том, что на рынке существует дефицит вакансий в данной сфере;
* если говорить о вакансия в сфере данных, то для большинства из них требуется знание sql и python. При этом в среднем необходимо обладать 6 навыками работы.

### Использованные инструменты и библиотеки
* pandas (1.5.2);
* psycopg2 (2.9.6);
* requests (2.28.2);
* bs4 (4.12.0);
* seaborn (0.12.2).

:arrow_up:[к Оглавлению](https://github.com/vadimkopytko/learning/blob/main/SkillFactory/PY-17_PROJECT-1/README.md#Оглавление)